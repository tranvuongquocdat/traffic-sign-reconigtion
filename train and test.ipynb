{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 30, 30, 3) (39209,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "data = []\n",
    "labels = []\n",
    "classes = 43\n",
    "cur_path = os.getcwd()\n",
    "#Retrieving the images and their labels \n",
    "for i in range(classes):\n",
    "    path = os.path.join(cur_path,'train',str(i))\n",
    "    images = os.listdir(path)\n",
    "    for a in images:\n",
    "        try:\n",
    "            image = Image.open(path + '\\\\'+ a)\n",
    "            image = image.resize((30,30))\n",
    "            image = np.array(image)\n",
    "            #sim = Image.fromarray(image)\n",
    "            data.append(image)\n",
    "            labels.append(i)\n",
    "        except:\n",
    "            print(\"Error loading image\")\n",
    "#Converting lists into numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print(data.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31367, 30, 30, 3) (7842, 30, 30, 3) (31367,) (7842,)\n"
     ]
    }
   ],
   "source": [
    "#Split the data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size= 0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes = 43)\n",
    "y_val = to_categorical(y_val, num_classes = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5), activation ='relu', input_shape = X_train.shape[1:]))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5), activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "model.add(Dropout(rate = 0.25))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "model.add(Dropout(rate = 0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dropout(rate =0.5))\n",
    "model.add(Dense(43, activation = 'softmax'))\n",
    "\n",
    "#Compilation of the model\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "491/491 [==============================] - 7s 6ms/step - loss: 3.9151 - accuracy: 0.0653 - val_loss: 3.1394 - val_accuracy: 0.1931\n",
      "Epoch 2/15\n",
      "491/491 [==============================] - 2s 5ms/step - loss: 2.0891 - accuracy: 0.4211 - val_loss: 1.0396 - val_accuracy: 0.7286\n",
      "Epoch 3/15\n",
      "491/491 [==============================] - 2s 5ms/step - loss: 1.1542 - accuracy: 0.6616 - val_loss: 0.5707 - val_accuracy: 0.8454\n",
      "Epoch 4/15\n",
      "491/491 [==============================] - 2s 5ms/step - loss: 0.8520 - accuracy: 0.7450 - val_loss: 0.4266 - val_accuracy: 0.8806\n",
      "Epoch 5/15\n",
      "491/491 [==============================] - 2s 5ms/step - loss: 0.6928 - accuracy: 0.7941 - val_loss: 0.4146 - val_accuracy: 0.8860\n",
      "Epoch 6/15\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.5819 - accuracy: 0.8270 - val_loss: 0.2728 - val_accuracy: 0.9287\n",
      "Epoch 7/15\n",
      "491/491 [==============================] - 2s 5ms/step - loss: 0.5435 - accuracy: 0.8377 - val_loss: 0.2152 - val_accuracy: 0.9435\n",
      "Epoch 8/15\n",
      "491/491 [==============================] - 2s 5ms/step - loss: 0.4825 - accuracy: 0.8582 - val_loss: 0.2000 - val_accuracy: 0.9494\n",
      "Epoch 9/15\n",
      "491/491 [==============================] - 2s 5ms/step - loss: 0.4360 - accuracy: 0.8709 - val_loss: 0.1756 - val_accuracy: 0.9532\n",
      "Epoch 10/15\n",
      "491/491 [==============================] - 2s 5ms/step - loss: 0.3891 - accuracy: 0.8861 - val_loss: 0.1651 - val_accuracy: 0.9588\n",
      "Epoch 11/15\n",
      "491/491 [==============================] - 2s 5ms/step - loss: 0.3719 - accuracy: 0.8904 - val_loss: 0.1638 - val_accuracy: 0.9543\n",
      "Epoch 12/15\n",
      "491/491 [==============================] - 2s 5ms/step - loss: 0.3461 - accuracy: 0.8986 - val_loss: 0.1053 - val_accuracy: 0.9725\n",
      "Epoch 13/15\n",
      "491/491 [==============================] - 3s 5ms/step - loss: 0.3090 - accuracy: 0.9086 - val_loss: 0.1259 - val_accuracy: 0.9685\n",
      "Epoch 14/15\n",
      "491/491 [==============================] - 2s 5ms/step - loss: 0.3115 - accuracy: 0.9094 - val_loss: 0.1666 - val_accuracy: 0.9540\n",
      "Epoch 15/15\n",
      "491/491 [==============================] - 2s 5ms/step - loss: 0.2997 - accuracy: 0.9156 - val_loss: 0.0952 - val_accuracy: 0.9763\n"
     ]
    }
   ],
   "source": [
    "#Train and validate the model\n",
    "history = model.fit(X_train, y_train, batch_size = 64, epochs = 15, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 3s 1ms/step\n",
      "0.9355502771179731\n"
     ]
    }
   ],
   "source": [
    "#testing accuracy on test dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "y_test = pd.read_csv('Test.csv')\n",
    "labels = y_test[\"ClassId\"].values\n",
    "imgs = y_test[\"Path\"].values\n",
    "data=[]\n",
    "for img in imgs:\n",
    "    image = Image.open(img)\n",
    "    image = image.resize((30,30))\n",
    "    data.append(np.array(image))\n",
    "X_test=np.array(data)\n",
    "predict_x=model.predict(X_test) \n",
    "pred = np.argmax(predict_x,axis=1)\n",
    "#Accuracy with the test data\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#test with real images\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "\n",
    "model = keras.models.load_model('model.h5')\n",
    "data = []\n",
    "\n",
    "#read images\n",
    "path = \"Test/00001.png\"\n",
    "image = Image.open(path)\n",
    "image = image.resize((30,30))\n",
    "data.append(np.array(image))\n",
    "\n",
    "X_test = np.array(data)\n",
    "predict_x=model.predict(X_test) \n",
    "pred = np.argmax(predict_x,axis=1)\n",
    "print(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference with onnx model\n",
    "import onnx\n",
    "onnx_model = onnx.load(\"traffic_sign.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2431, 0.3490, 0.3686,  ..., 0.3059, 0.2824, 0.2902],\n",
      "         [0.2510, 0.3804, 0.3804,  ..., 0.2941, 0.3647, 0.3451],\n",
      "         [0.2314, 0.3569, 0.3725,  ..., 0.2667, 0.2980, 0.3059],\n",
      "         ...,\n",
      "         [0.2039, 0.3176, 0.3137,  ..., 0.2745, 0.3255, 0.3059],\n",
      "         [0.2078, 0.3137, 0.3059,  ..., 0.2314, 0.2627, 0.2824],\n",
      "         [0.2118, 0.3137, 0.3059,  ..., 0.2431, 0.2824, 0.2941]],\n",
      "\n",
      "        [[0.2824, 0.3176, 0.3216,  ..., 0.2510, 0.2549, 0.2667],\n",
      "         [0.2824, 0.3255, 0.3176,  ..., 0.2471, 0.2706, 0.2667],\n",
      "         [0.2784, 0.3255, 0.3176,  ..., 0.2471, 0.2627, 0.2706],\n",
      "         ...,\n",
      "         [0.2000, 0.2706, 0.2627,  ..., 0.2471, 0.2627, 0.2588],\n",
      "         [0.1961, 0.2627, 0.2549,  ..., 0.2314, 0.2549, 0.2588],\n",
      "         [0.1922, 0.2588, 0.2588,  ..., 0.2275, 0.2588, 0.2745]],\n",
      "\n",
      "        [[0.2392, 0.2471, 0.2549,  ..., 0.2667, 0.2627, 0.2667],\n",
      "         [0.2353, 0.2549, 0.2471,  ..., 0.2549, 0.2784, 0.2667],\n",
      "         [0.2353, 0.2588, 0.2471,  ..., 0.2471, 0.2667, 0.2745],\n",
      "         ...,\n",
      "         [0.1804, 0.2275, 0.2235,  ..., 0.2471, 0.2588, 0.2627],\n",
      "         [0.1882, 0.2431, 0.2314,  ..., 0.2392, 0.2510, 0.2588],\n",
      "         [0.1882, 0.2431, 0.2275,  ..., 0.2392, 0.2706, 0.2745]]])\n"
     ]
    },
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Invalid Feed Input Name:input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [35], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m x \u001b[39m=\u001b[39m img[\u001b[39m0\u001b[39m]\n\u001b[0;32m     15\u001b[0m ort_sess \u001b[39m=\u001b[39m ort\u001b[39m.\u001b[39mInferenceSession(\u001b[39m'\u001b[39m\u001b[39mtraffic_sign.onnx\u001b[39m\u001b[39m'\u001b[39m, providers\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mTensorrtExecutionProvider\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCUDAExecutionProvider\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCPUExecutionProvider\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 16\u001b[0m outputs \u001b[39m=\u001b[39m ort_sess\u001b[39m.\u001b[39mrun(\u001b[39mNone\u001b[39;00m, {\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m: x\u001b[39m.\u001b[39mnumpy()})\n\u001b[0;32m     18\u001b[0m \u001b[39m# Print Result \u001b[39;00m\n\u001b[0;32m     19\u001b[0m predicted, actual \u001b[39m=\u001b[39m classes[outputs[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39margmax(\u001b[39m0\u001b[39m)], classes[y]\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:200\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[0;32m    198\u001b[0m     output_names \u001b[39m=\u001b[39m [output\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs_meta]\n\u001b[0;32m    199\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sess\u001b[39m.\u001b[39;49mrun(output_names, input_feed, run_options)\n\u001b[0;32m    201\u001b[0m \u001b[39mexcept\u001b[39;00m C\u001b[39m.\u001b[39mEPFail \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    202\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_fallback:\n",
      "\u001b[1;31mInvalidArgument\u001b[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Invalid Feed Input Name:input"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "#read images\n",
    "path = \"Test/00001.png\"\n",
    "image = Image.open(path)\n",
    "image = image.resize((30,30))\n",
    "convert_tensor = transforms.ToTensor()\n",
    "img = convert_tensor(image)\n",
    "print(img)\n",
    "x = img[0]\n",
    "ort_sess = ort.InferenceSession('traffic_sign.onnx', providers=['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "outputs = ort_sess.run(None, {'input': x.numpy()})\n",
    "\n",
    "# Print Result \n",
    "predicted, actual = classes[outputs[0][0].argmax(0)], classes[y]\n",
    "print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from onnx import numpy_helper\n",
    "\n",
    "model = \"traffic_sign.onnx\"\n",
    "path = \"Test/00064.png\"\n",
    "\n",
    "def Predict(path = path, model = model):\n",
    "    #Preprocess the image\n",
    "    image = cv2.imread(path)\n",
    "    img = np.dot(image[...,:3], [0.299, 0.587, 0.114])\n",
    "    img = cv2.resize(img, dsize=(30, 30), interpolation=cv2.INTER_AREA)\n",
    "    img.resize((64, 30, 30, 3))\n",
    "    \n",
    "    data = json.dumps({'data': img.tolist()})\n",
    "    data = np.array(json.loads(data)['data']).astype('float32')\n",
    "\n",
    "    session = onnxruntime.InferenceSession(model, None, providers=['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_name = session.get_outputs()[0].name\n",
    "    print(input_name)\n",
    "    print(output_name)\n",
    "    \n",
    "    result = session.run([output_name], {input_name: data})\n",
    "    print(result)\n",
    "    prediction=int(np.argmax(np.array(result[0][1]).squeeze(), axis=0))\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_input\n",
      "dense_1\n",
      "[array([[6.5278838e-10, 1.8887455e-03, 7.5699150e-05, ..., 8.2840561e-05,\n",
      "        1.0507074e-04, 2.7158969e-06],\n",
      "       [1.7727014e-07, 2.1392223e-01, 8.3310455e-03, ..., 1.9076566e-03,\n",
      "        7.6611835e-04, 1.6631815e-05],\n",
      "       [1.7727014e-07, 2.1392223e-01, 8.3310455e-03, ..., 1.9076566e-03,\n",
      "        7.6611835e-04, 1.6631815e-05],\n",
      "       ...,\n",
      "       [1.7727014e-07, 2.1392223e-01, 8.3310455e-03, ..., 1.9076566e-03,\n",
      "        7.6611835e-04, 1.6631815e-05],\n",
      "       [1.7727014e-07, 2.1392223e-01, 8.3310455e-03, ..., 1.9076566e-03,\n",
      "        7.6611835e-04, 1.6631815e-05],\n",
      "       [1.7727014e-07, 2.1392223e-01, 8.3310455e-03, ..., 1.9076566e-03,\n",
      "        7.6611835e-04, 1.6631815e-05]], dtype=float32)]\n",
      "1\n",
      "conv2d_input\n",
      "dense_1\n",
      "[array([[5.9890309e-10, 1.1146225e-03, 4.5248889e-05, ..., 1.3538054e-04,\n",
      "        1.9246378e-05, 3.0916749e-06],\n",
      "       [1.7727012e-07, 2.1392222e-01, 8.3310446e-03, ..., 1.9076582e-03,\n",
      "        7.6611835e-04, 1.6631813e-05],\n",
      "       [1.7727012e-07, 2.1392222e-01, 8.3310446e-03, ..., 1.9076582e-03,\n",
      "        7.6611835e-04, 1.6631813e-05],\n",
      "       ...,\n",
      "       [1.7727012e-07, 2.1392222e-01, 8.3310446e-03, ..., 1.9076582e-03,\n",
      "        7.6611835e-04, 1.6631813e-05],\n",
      "       [1.7727012e-07, 2.1392222e-01, 8.3310446e-03, ..., 1.9076582e-03,\n",
      "        7.6611835e-04, 1.6631813e-05],\n",
      "       [1.7727012e-07, 2.1392222e-01, 8.3310446e-03, ..., 1.9076582e-03,\n",
      "        7.6611835e-04, 1.6631813e-05]], dtype=float32)]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "Predict(path = \"Test/00064.png\")\n",
    "Predict(path = \"Test/00062.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e593ac106456af50ce7af38f9671c411b49d6cd90f9b885e167f0f594e09038c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
